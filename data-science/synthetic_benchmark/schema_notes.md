# Schema Notes – Synthetic Benchmark (AI Navigator MVP)

**Author:** Vicky Barocsai  
**Date:** 2025-10-24  
**Purpose:** Define all dataset schemas generated by `generate_synthetic_benchmark.ipynb`  
**Coverage:** Milestones 1–4 (Data Science Deliverables)

---

## 1. Capability Benchmark – Flat Table

**File:** `/public/demo_data/sample_capability.csv`  
**Used by:** CSV upload validation / backend schema testing

| Field | Type | Description |
| ------ | ------ | ------ |
| dimension | string | Capability dimension (e.g., "Data", "Technology"). |
| construct | string | Construct within the dimension (1–4 per dimension). |
| benchmark_mean | float | Average benchmark score (0–100 scale). |
| benchmark_min | float | Lower bound (mean – 2 SD). |
| benchmark_max | float | Upper bound (mean + 2 SD). |

---

## 2. Capability Benchmark – API Nested JSON

**File:** `/public/demo_data/benchmark.json`  
**Used by:** `/api/benchmark/:industry/:region` endpoint

**Structure Example:**

```json
{
  "benchmark_name": "Synthetic OECD Benchmark",
  "benchmark_type": "synthetic",
  "created_at": "2025-10-24",
  "data": [
    {
      "dimension": "Data",
      "constructs": [
        {
          "construct": "Data Construct 1",
          "benchmark_mean": 73.2,
          "benchmark_min": 58.0,
          "benchmark_max": 89.1
        }
      ]
    }
  ]
}
```
Variants:
- /public/demo_data/benchmark_region_eu.json (+2 mean offset)
- /public/demo_data/benchmark_region_na.json (−2 mean offset)

## 3. Sentiment Benchmark – 25 Zones

Files:

/public/demo_data/sample_sentiment.csv

/public/demo_data/sentiment_preview.json

Used by: /api/sentiment/heatmap and frontend heatmap

Field	Type	Description
area_id	integer	Zone ID (1–25).
area_name	string	Label (e.g., "Sentiment Area 5").
sentiment_score	integer	Score (0–100; typically 40–90).
benchmark_type	string	"synthetic".

Color Scale Guidance:
Low (<55): Red
Mid (~70): Yellow
High (>85): Green

## 4. Dimension Benchmark & Gap Examples

Files:
- /public/demo_data/dimension_benchmark.json
- /public/demo_data/gap_examples.csv

| Field | Type | Description |
| ------ | ------ | ------ |
| dimension | string | Dimension name. |
| dimension_benchmark_mean | float | Average benchmark mean per dimension. |
| actual_score | float | Simulated organization score (0–100). |
| gap | float | actual_score − benchmark_mean. |


## 5. Intervention Rules

**File:** `/public/demo_data/intervention_rules.json`  
**Used by:** `/api/interventions/recommend`

| Field | Type | Description |
| ------ | ------ | ------ |
| threshold | integer | Trigger limit for intervention. |
| applies_to | string | "construct" or "dimension". |
| intervention | string | Recommended action label. |

**Example:**

```json
[
  {
    "threshold": 60,
    "applies_to": "construct",
    "intervention": "Targeted Training"
  },
  {
    "threshold": 55,
    "applies_to": "construct",
    "intervention": "Data Quality Uplift"
  },
  {
    "threshold": 65,
    "applies_to": "dimension",
    "intervention": "Leadership Alignment"
  }
]

```

## 6. ROI Glimpse Table

**File:** `/public/demo_data/sample_roi.csv`  
**Used by:** `/api/roi/:interventionId`

| Field | Type | Description |
| ------ | ------ | ------ |
| dimension | string | Capability area. |
| construct | string | Construct within dimension. |
| gain_low | integer | Lower expected gain (%). |
| gain_high | integer | Upper expected gain (%). |

**Typical Range:** 5–15%


## 7. Acceptance Criteria (Confirmed)

- All files exist under `/public/demo_data/`.  
- JSON objects are valid and schema-consistent.  
- Scores range 0–100 and look plausible (40–90 typical).  
- Developers can load each file directly into their API mock endpoints.  
- Structure matches API expectations for:  
  - `/api/benchmark`  
  - `/api/sentiment/heatmap`  
  - `/api/interventions/recommend`  
  - `/api/roi/:id`

